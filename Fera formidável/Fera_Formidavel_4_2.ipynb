{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e52ca1",
   "metadata": {},
   "source": [
    "## 4.2 - Stop right now, thank you very much\n",
    "\n",
    "\n",
    "#### Aluna: Ana Luiza Poletto Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563f7f2",
   "metadata": {},
   "source": [
    "**Objetivo**: implemente uma estratégia de Parada Antecipada (Early Stopping) no processo de treino da rede neural feita em Python puro ou no processo de treino da rede neural feita em PyTorch.\n",
    "\n",
    "Comentário: esta não é para resolver com o módulo lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d4d1e",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8308c3",
   "metadata": {},
   "source": [
    "As redes neurais, quando treinadas por muitas épocas, correm o risco de sofrer overfitting, ou seja, se ajustarem demais aos dados de treino, perdendo capacidade de generalização. Uma estratégia eficiente para diminuir esse problema é o uso de parada antecipada (Early Stopping). Ela interrompe o treinamento quando a performance na base de validação deixa de melhorar, evitando treinamento desnecessário e sobreajuste.\n",
    "\n",
    "Este notebook tem como objetivo implementar uma rede neural simples usando `PyTorch`, treinada para prever a largura da pétala da espécie Iris virginica com base em outras características. Além disso, aplicamos a técnica de Early Stopping, monitorando a perda na base de validação.\n",
    "\n",
    "\n",
    "##### Considerações\n",
    "\n",
    "*O PyTorch é uma biblioteca de aprendizado de máquina muito utilizada para desenvolvimento de modelos de deep learning (O QUE É PYTORCH?, 2025). A técnica de Early Stopping permite interromper o treinamento da rede neural quando ela para de melhorar, evitando overfitting (CYBORG CODES, 2021). A implementação proposta segue a estrutura apresentada no notebook da disciplina (CASSAR, 2025).*\n",
    "\n",
    "*Além disso, o texto colocado aqui foi revisado pelo modelo de linguagem.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dbc74",
   "metadata": {},
   "source": [
    "####  Desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c50c4",
   "metadata": {},
   "source": [
    "Importamos bibliotecas essenciais: \n",
    "\n",
    "- `PyTorch` para construir e treinar a rede, `sklearn` para divisão dos dados e cálculo do erro, e `Seaborn/Matplotlib` para carregamento e visualização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da486207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b06c01",
   "metadata": {},
   "source": [
    "Carregamos o `dataset` Iris que contém informações sobre flores, como comprimento e largura das sépalas e pétalas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b67b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flores = sns.load_dataset('iris')\n",
    "flores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1135c",
   "metadata": {},
   "source": [
    "Filtramos apenas a espécie virginica e selecionamos três características como entrada e uma como alvo o tamanho da pétala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e779b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "100           6.3          3.3           6.0          2.5  virginica\n",
       "101           5.8          2.7           5.1          1.9  virginica\n",
       "102           7.1          3.0           5.9          2.1  virginica\n",
       "103           6.3          2.9           5.6          1.8  virginica\n",
       "104           6.5          3.0           5.8          2.2  virginica\n",
       "105           7.6          3.0           6.6          2.1  virginica\n",
       "106           4.9          2.5           4.5          1.7  virginica\n",
       "107           7.3          2.9           6.3          1.8  virginica\n",
       "108           6.7          2.5           5.8          1.8  virginica\n",
       "109           7.2          3.6           6.1          2.5  virginica\n",
       "110           6.5          3.2           5.1          2.0  virginica\n",
       "111           6.4          2.7           5.3          1.9  virginica\n",
       "112           6.8          3.0           5.5          2.1  virginica\n",
       "113           5.7          2.5           5.0          2.0  virginica\n",
       "114           5.8          2.8           5.1          2.4  virginica\n",
       "115           6.4          3.2           5.3          2.3  virginica\n",
       "116           6.5          3.0           5.5          1.8  virginica\n",
       "117           7.7          3.8           6.7          2.2  virginica\n",
       "118           7.7          2.6           6.9          2.3  virginica\n",
       "119           6.0          2.2           5.0          1.5  virginica\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = [\"sepal_length\", \"sepal_width\", \"petal_length\"]\n",
    "target = [\"petal_width\"]\n",
    "\n",
    "filtro = flores[\"species\"] == \"virginica\"\n",
    "flores = flores.loc[filtro]\n",
    "\n",
    "flores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d3d40",
   "metadata": {},
   "source": [
    "Organizamos os dados, retirando possíveis valores ausentes e separando em variáveis X (entradas) e y (alvo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc49fbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "100           6.3          3.3           6.0          2.5\n",
       "101           5.8          2.7           5.1          1.9\n",
       "102           7.1          3.0           5.9          2.1\n",
       "103           6.3          2.9           5.6          1.8\n",
       "104           6.5          3.0           5.8          2.2\n",
       "105           7.6          3.0           6.6          2.1\n",
       "106           4.9          2.5           4.5          1.7\n",
       "107           7.3          2.9           6.3          1.8\n",
       "108           6.7          2.5           5.8          1.8\n",
       "109           7.2          3.6           6.1          2.5\n",
       "110           6.5          3.2           5.1          2.0\n",
       "111           6.4          2.7           5.3          1.9\n",
       "112           6.8          3.0           5.5          2.1\n",
       "113           5.7          2.5           5.0          2.0\n",
       "114           5.8          2.8           5.1          2.4\n",
       "115           6.4          3.2           5.3          2.3\n",
       "116           6.5          3.0           5.5          1.8\n",
       "117           7.7          3.8           6.7          2.2\n",
       "118           7.7          2.6           6.9          2.3\n",
       "119           6.0          2.2           5.0          1.5\n",
       "120           6.9          3.2           5.7          2.3\n",
       "121           5.6          2.8           4.9          2.0\n",
       "122           7.7          2.8           6.7          2.0\n",
       "123           6.3          2.7           4.9          1.8\n",
       "124           6.7          3.3           5.7          2.1\n",
       "125           7.2          3.2           6.0          1.8\n",
       "126           6.2          2.8           4.8          1.8\n",
       "127           6.1          3.0           4.9          1.8\n",
       "128           6.4          2.8           5.6          2.1\n",
       "129           7.2          3.0           5.8          1.6\n",
       "130           7.4          2.8           6.1          1.9\n",
       "131           7.9          3.8           6.4          2.0\n",
       "132           6.4          2.8           5.6          2.2\n",
       "133           6.3          2.8           5.1          1.5\n",
       "134           6.1          2.6           5.6          1.4\n",
       "135           7.7          3.0           6.1          2.3\n",
       "136           6.3          3.4           5.6          2.4\n",
       "137           6.4          3.1           5.5          1.8\n",
       "138           6.0          3.0           4.8          1.8\n",
       "139           6.9          3.1           5.4          2.1\n",
       "140           6.7          3.1           5.6          2.4\n",
       "141           6.9          3.1           5.1          2.3\n",
       "142           5.8          2.7           5.1          1.9\n",
       "143           6.8          3.2           5.9          2.3\n",
       "144           6.7          3.3           5.7          2.5\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flores = flores.reindex(feature + target, axis=1)\n",
    "flores = flores.dropna()\n",
    "\n",
    "X = flores[feature].values\n",
    "y = flores[target].values.reshape(-1,1)\n",
    "\n",
    "flores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9387e",
   "metadata": {},
   "source": [
    "Dividimos os dados em treino (20%), validação (20%) e teste (60%), garantindo aleatoriedade controlada com uma semente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46167b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMENTE = 25\n",
    "\n",
    "train_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, random_state=SEMENTE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=SEMENTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6c32c",
   "metadata": {},
   "source": [
    "Convertendo os dados `numpy` para tensores do `PyTorch`, que é o formato necessário para o treinamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daf9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    " \n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    " \n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0a789",
   "metadata": {},
   "source": [
    "Criamos uma rede neural com duas camadas ocultas utilizando a classe `nn.Module` do PyTorch. As ativações são Sigmoid e a saída é linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdbf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_dados_entrada, neuronios_c1, neuronios_c2, num_targets):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.camadas = nn.Sequential(\n",
    "            nn.Linear(num_dados_entrada, neuronios_c1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(neuronios_c1, neuronios_c2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(neuronios_c2, num_targets),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.camadas(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23880c9",
   "metadata": {},
   "source": [
    "Instanciamos a rede com 3 entradas (features), 2 camadas ocultas e 1 saída (alvo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84f84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = 3  \n",
    "NUM_DADOS_DE_SAIDA = 1  \n",
    "NEURONIOS_C1 = 3\n",
    "NEURONIOS_C2 = 2\n",
    "\n",
    "minha_mlp = MLP(\n",
    "    NUM_DADOS_DE_ENTRADA, NEURONIOS_C1, NEURONIOS_C2, NUM_DADOS_DE_SAIDA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbaab2",
   "metadata": {},
   "source": [
    "Utilizamos o otimizador SGD (Gradiente Estocástico) e a função de perda MSELoss (erro quadrático médio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63b9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXA_DE_APRENDIZADO = 0.001\n",
    "\n",
    "otimizador = optim.SGD(minha_mlp.parameters(), lr=TAXA_DE_APRENDIZADO)\n",
    "\n",
    "fn_perda = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b717d",
   "metadata": {},
   "source": [
    "Definimos os parâmetros do Early Stopping:\n",
    "\n",
    "- PATIENCE: quantidade de épocas consecutivas sem melhora necessária para parar (10).\n",
    "\n",
    "- DELTA: variação mínima aceitável para considerar uma melhora (0.01).\n",
    "\n",
    "E então começamos o treinamento da rede com o Early Stopping. O loop executa as seguintes etapas:\n",
    "\n",
    "*Treino:*\n",
    "\n",
    "- Faz forward pass, calcula a perda e atualiza os pesos.\n",
    "\n",
    "*Validação:*\n",
    "\n",
    "- Calcula a perda na base de validação.\n",
    "\n",
    "*Early Stopping:*\n",
    "\n",
    "- Compara a perda atual da validação com a anterior.\n",
    "\n",
    "- Se a melhora for menor que DELTA, incrementa um contador.\n",
    "\n",
    "- Se isso acontecer por PATIENCE épocas consecutivas, o treinamento para."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a016140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3.2025)\n",
      "1 tensor(3.1820)\n",
      "2 tensor(3.1616)\n",
      "3 tensor(3.1413)\n",
      "4 tensor(3.1212)\n",
      "5 tensor(3.1013)\n",
      "6 tensor(3.0814)\n",
      "7 tensor(3.0618)\n",
      "8 tensor(3.0422)\n",
      "9 tensor(3.0228)\n",
      "10 tensor(3.0036)\n",
      "11 tensor(2.9844)\n",
      "12 tensor(2.9654)\n",
      "13 tensor(2.9466)\n",
      "14 tensor(2.9278)\n",
      "15 tensor(2.9092)\n",
      "16 tensor(2.8908)\n",
      "17 tensor(2.8724)\n",
      "18 tensor(2.8542)\n",
      "19 tensor(2.8361)\n",
      "20 tensor(2.8182)\n",
      "21 tensor(2.8003)\n",
      "22 tensor(2.7826)\n",
      "23 tensor(2.7650)\n",
      "24 tensor(2.7476)\n",
      "25 tensor(2.7302)\n",
      "26 tensor(2.7130)\n",
      "27 tensor(2.6959)\n",
      "28 tensor(2.6789)\n",
      "29 tensor(2.6620)\n",
      "30 tensor(2.6453)\n",
      "31 tensor(2.6286)\n",
      "32 tensor(2.6121)\n",
      "33 tensor(2.5957)\n",
      "34 tensor(2.5794)\n",
      "35 tensor(2.5632)\n",
      "36 tensor(2.5472)\n",
      "37 tensor(2.5312)\n",
      "38 tensor(2.5153)\n",
      "39 tensor(2.4996)\n",
      "40 tensor(2.4840)\n",
      "41 tensor(2.4684)\n",
      "42 tensor(2.4530)\n",
      "43 tensor(2.4377)\n",
      "44 tensor(2.4225)\n",
      "45 tensor(2.4074)\n",
      "46 tensor(2.3924)\n",
      "47 tensor(2.3774)\n",
      "48 tensor(2.3626)\n",
      "49 tensor(2.3479)\n",
      "50 tensor(2.3333)\n",
      "51 tensor(2.3188)\n",
      "52 tensor(2.3044)\n",
      "53 tensor(2.2901)\n",
      "54 tensor(2.2759)\n",
      "55 tensor(2.2618)\n",
      "56 tensor(2.2477)\n",
      "57 tensor(2.2338)\n",
      "58 tensor(2.2200)\n",
      "59 tensor(2.2062)\n",
      "60 tensor(2.1926)\n",
      "61 tensor(2.1790)\n",
      "62 tensor(2.1655)\n",
      "63 tensor(2.1522)\n",
      "64 tensor(2.1389)\n",
      "65 tensor(2.1257)\n",
      "66 tensor(2.1126)\n",
      "67 tensor(2.0995)\n",
      "68 tensor(2.0866)\n",
      "69 tensor(2.0737)\n",
      "70 tensor(2.0610)\n",
      "71 tensor(2.0483)\n",
      "72 tensor(2.0357)\n",
      "73 tensor(2.0232)\n",
      "74 tensor(2.0107)\n",
      "75 tensor(1.9984)\n",
      "76 tensor(1.9861)\n",
      "77 tensor(1.9739)\n",
      "78 tensor(1.9618)\n",
      "79 tensor(1.9498)\n",
      "80 tensor(1.9378)\n",
      "81 tensor(1.9260)\n",
      "82 tensor(1.9142)\n",
      "83 tensor(1.9025)\n",
      "84 tensor(1.8908)\n",
      "85 tensor(1.8793)\n",
      "86 tensor(1.8678)\n",
      "87 tensor(1.8564)\n",
      "88 tensor(1.8451)\n",
      "89 tensor(1.8338)\n",
      "90 tensor(1.8226)\n",
      "91 tensor(1.8115)\n",
      "92 tensor(1.8005)\n",
      "93 tensor(1.7895)\n",
      "94 tensor(1.7786)\n",
      "95 tensor(1.7678)\n",
      "96 tensor(1.7570)\n",
      "97 tensor(1.7463)\n",
      "98 tensor(1.7357)\n",
      "99 tensor(1.7252)\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 100\n",
    "PATIENCE = 10\n",
    "DELTA = 0.01\n",
    "\n",
    "perda_treino = []\n",
    "perda_validacao = []\n",
    "contador = 0\n",
    "\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    \n",
    "    minha_mlp.train()\n",
    "    # forward pass\n",
    "    y_pred = minha_mlp(X_train)\n",
    "\n",
    "    # zero grad\n",
    "    otimizador.zero_grad()\n",
    "\n",
    "    # loss\n",
    "    loss = fn_perda(y_train, y_pred)\n",
    "    perda_treino.append(loss)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # atualiza parâmetros\n",
    "    otimizador.step()\n",
    "\n",
    "    # mostra resultado (opcional)\n",
    "    print(epoca, loss.data)\n",
    "    \n",
    "    \n",
    "    # VALIDAÇÃO \n",
    "    minha_mlp.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # forward pass\n",
    "        y_pred = minha_mlp(X_val)\n",
    " \n",
    "        # calcula perda\n",
    "        perda_validacao += [fn_perda(y_val, y_pred).data]\n",
    "        \n",
    "    \n",
    "    # EARLY STOPPING\n",
    "    penultimo_indice = len(perda_validacao) - 2\n",
    "    penultimo_valor = perda_validacao[penultimo_indice]\n",
    "\n",
    "    diferenca = abs(ultimo_valor - penultimo_valor)\n",
    "\n",
    "    if diferenca <= DELTA:\n",
    "        contador += 1\n",
    "    else:\n",
    "        contador = 0\n",
    "\n",
    "    if contador == PATIENCE:\n",
    "        parada = epoca\n",
    "        print(f'Época de parada: {parada}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd35ee",
   "metadata": {},
   "source": [
    "A rede é colocada em modo de avaliação e faz previsões sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4949572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7219],\n",
       "        [0.7226],\n",
       "        [0.7194],\n",
       "        [0.7234],\n",
       "        [0.7265],\n",
       "        [0.7230],\n",
       "        [0.7228],\n",
       "        [0.7236],\n",
       "        [0.7230],\n",
       "        [0.7245],\n",
       "        [0.7249],\n",
       "        [0.7200],\n",
       "        [0.7209],\n",
       "        [0.7217],\n",
       "        [0.7231],\n",
       "        [0.7217],\n",
       "        [0.7262],\n",
       "        [0.7209],\n",
       "        [0.7214],\n",
       "        [0.7238],\n",
       "        [0.7258],\n",
       "        [0.7256],\n",
       "        [0.7230],\n",
       "        [0.7219],\n",
       "        [0.7229],\n",
       "        [0.7183],\n",
       "        [0.7286],\n",
       "        [0.7248],\n",
       "        [0.7252],\n",
       "        [0.7220]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minha_mlp.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_previsto = minha_mlp(X_test)\n",
    "    \n",
    "y_previsto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72ddf3",
   "metadata": {},
   "source": [
    "Calculamos o RMSE (Root Mean Squared Error), que mede o quão bem a rede conseguiu prever no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb36857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3013108\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(y_test, y_previsto, squared=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c541a7",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c170f",
   "metadata": {},
   "source": [
    "O experimento obteve sucesso na implementação de uma rede neural simples com o PyTorch e na aplicação da estratégia de Early Stopping. Observou-se uma redução contínua da perda durante o treinamento, indicando que o modelo conseguiu aprender os padrões dos dados.\n",
    "\n",
    "O RMSE de aproximadamente 1.30 reflete um erro razoável, dado o tamanho pequeno do dataset e a simplicidade da rede. A técnica de Early Stopping, apesar de não ter sido ativada neste caso, foi corretamente implementada, pronta para interromper o treinamento caso a melhora na validação estagnasse, o que é uma estratégia eficaz para evitar overfitting em modelos mais complexos ou datasets maiores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08a012",
   "metadata": {},
   "source": [
    "### Referências\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95377f76",
   "metadata": {},
   "source": [
    "O QUE É PYTORCH? IBM. Disponível em: https://www.ibm.com/br-pt/think/topics/pytorch. Acesso em: 12 jun. 2025.\n",
    "\n",
    "CASSAR, Daniel Roberto. ATP-303 NN 5.2 — Notebook PyTorch. 2025.\n",
    "\n",
    "CYBORG CODES. What is Early Stopping in Deep Learning? Medium. Disponível em: https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf. Acesso em: 13 jun. 2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
